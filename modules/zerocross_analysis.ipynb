{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '..')\n",
    "sys.path.insert(2, '../modules/')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from datetime import timedelta\n",
    "from modules import convert_datetime\n",
    "import dataconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_list = []\n",
    "glob_str = f'{dataconfig.DATA_DIR_ZERO_CROSS}/*zero_cross_df.pickle'\n",
    "for file in glob(glob_str):\n",
    "    input_data = pickle.load(open(file, 'rb'))\n",
    "\n",
    "    merged_df_list.append(input_data)\n",
    "\n",
    "merged_zerocross_df = pd.concat(merged_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hek_flares = pickle.load(open('/data/padialjr/jorge-helio/data_products/hek_flare_db.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flare_class_dict_query = {'A': 1e-8, 'B': 1e-7, 'C': 1e-6, 'M': 1e-5, 'X': 1e-4}\n",
    "teams = {'ALEXIS': 1, 'SWPC': 2, 'SolarSoft':4}  \n",
    "# tuples are (ALEXIS, SWPC, solar_soft)    \n",
    "id_dict = {'7':(1,1,1), '6': (0,1,1), '5': (1,0,1),'4': (0,0,1),'3': (1,1,0),'2': (0,1,0),'1': (1,0,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goes_flares = hek_flares[(hek_flares['id_team'] == 'SWPC')& (hek_flares['goes_class'] > 'C')].reset_index(drop= True)\n",
    "\n",
    "solarsoft_flares = hek_flares[(hek_flares['id_team'] == 'SolarSoft') & (hek_flares['goes_class'] > 'C')].reset_index(drop= True)\n",
    "\n",
    "zero_cross = merged_zerocross_df[(merged_zerocross_df['resampled_value'] > flare_class_dict_query['C'])].reset_index(drop= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our zero crossing df\n",
    "\n",
    "our_flares = zero_cross[['zerocross_date_time']]\n",
    "\n",
    "our_flares['id_team'] = 'ALEXIS'\n",
    "\n",
    "only_duplicated_zero = our_flares[(our_flares.duplicated())]\n",
    "\n",
    "zero_flares = our_flares.rename(columns = {'zerocross_date_time': 'peak_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define SWPC Flares\n",
    "\n",
    "goes_flares = pd.DataFrame(goes_flares.peak_time, columns = ['peak_time'])\n",
    "\n",
    "goes_flares['id_team'] = 'SWPC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define solarsoft flares\n",
    "\n",
    "solarsoft_flares = pd.DataFrame(solarsoft_flares.peak_time, columns = ['peak_time'])\n",
    "\n",
    "solarsoft_flares['id_team'] = 'SolarSoft'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flares_not_masked = pd.concat([zero_flares , goes_flares,  solarsoft_flares], ignore_index=True)\n",
    "\n",
    "date_limit_low, date_limit_high = pd.Timestamp('2010/5/1T00:00:00', tz = 'utc'),pd.Timestamp('2020/3/4T00:00:00', tz = 'utc')\n",
    "\n",
    "all_flares = all_flares_not_masked[(all_flares_not_masked.peak_time >= date_limit_low) & (all_flares_not_masked.peak_time <= date_limit_high)].sort_values(by = 'peak_time').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_per_agg = 10\n",
    "\n",
    "j = 0 # grab first datetime in the list\n",
    "flares_list = [] # keep track of info from loop\n",
    "\n",
    "while j < len(all_flares.peak_time):\n",
    "    \n",
    "    datetime = all_flares.peak_time.iloc[j] # grab j-th datetime\n",
    "        \n",
    "    fwd = datetime + timedelta(minutes = minutes_per_agg) # choose fwd time range\n",
    "     \n",
    "    mask = all_flares[(all_flares.peak_time < fwd) & (all_flares.peak_time >= datetime)] # return df with all entries from current datetime to fwd time\n",
    "    \n",
    "    this_flare_datetime_list = []\n",
    "    \n",
    "    this_flare_identification = []\n",
    "    \n",
    "    for group in teams: \n",
    "        \n",
    "        group_mask = mask[(mask.id_team) == group] #filter for all elements of mask that are returned by each individual group\n",
    "        \n",
    "        number_of_entries = len(group_mask)\n",
    "        \n",
    "        if number_of_entries != 0:\n",
    "        \n",
    "            mean_datetime = np.mean(group_mask.peak_time)\n",
    "            \n",
    "            this_flare_datetime_list.append({'datetime': mean_datetime})\n",
    "            \n",
    "            this_flare_identification.append(teams[group])\n",
    "                   \n",
    "        \n",
    "    sum_of_ids = np.sum(this_flare_identification)\n",
    "    \n",
    "    flare_id_tuple = id_dict[str(sum_of_ids)]\n",
    "    \n",
    "    datetime_df = pd.DataFrame(this_flare_datetime_list)\n",
    "    \n",
    "    merged_datetime = np.mean(datetime_df.datetime)\n",
    "            \n",
    "    flares_list.append({'merged_datetime': merged_datetime,\n",
    "                        'id_tuple': flare_id_tuple})\n",
    "    \n",
    "    k = len(mask) # go k amount fwd in the list of datetimes\n",
    "\n",
    "    j = j + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flare_list_df = pd.DataFrame(flares_list)\n",
    "flare_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_this = []\n",
    "for name,group in pd.DataFrame(flares_list).groupby('id_tuple'):\n",
    "    \n",
    "    plot_this.append({'id_tuple': name, \n",
    "                     'counts': len(group)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = pd.DataFrame(plot_this)\n",
    "\n",
    "stat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "# Example data\n",
    "id_tuple = stat_df.id_tuple.to_list()\n",
    "y_pos = np.arange(len(id_tuple))\n",
    "counts = stat_df.counts.to_list()\n",
    "# error = np.random.rand(len(people))\n",
    "\n",
    "\n",
    "\n",
    "hbars = ax.barh(y_pos, counts, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(id_tuple)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('counts')\n",
    "ax.set_ylabel('id_tuple == (jonas_lab, SWPC, solarsoft)')\n",
    "ax.set_title('id_tuple == (jonas_lab, SWPC, solarsoft) @ {} minute fwd time'.format(minutes_per_agg))\n",
    "\n",
    "for bar in hbars:\n",
    "    print(bar.get_y())\n",
    "    ax.text(bar.get_width(), bar.get_y(), s = bar.get_width(), va = 'center')\n",
    "\n",
    "ax.set_xscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiadl_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
