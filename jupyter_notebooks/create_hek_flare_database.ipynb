{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '..')\n",
    "sys.path.insert(2, '../modules/')\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from sunpy.time import TimeRange\n",
    "import sunpy.instr.goes\n",
    "import time\n",
    "from time import timezone\n",
    "from sunpy.net import hek\n",
    "from sunpy.time import parse_time\n",
    "\n",
    "from sunpy.net import hek\n",
    "from sunpy.time import parse_time\n",
    "import numpy as np\n",
    "from ruffus import *\n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import dataconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = 'flare_hekQ.working'\n",
    "\n",
    "tw = lambda x: os.path.join(WORKING_DIR, x)\n",
    "\n",
    "# create initial time pairs for running through the hek AR query by month\n",
    "time_array = []\n",
    "\n",
    "x = pd.date_range(start='4/01/2010', end='11/30/2020', freq = 'M')\n",
    "\n",
    "# x starts with the end date of april such that for every starting point we need to add an extra day such that we begin in the same month as the end month. \n",
    "for previous, current in zip(x, x[1:]):\n",
    "    j = ([previous + timedelta(days = 1), current ])\n",
    "    my_dict = {'name': '{}_{}_flare_hek'.format(previous.year, previous.month),\n",
    "    \t\t\t'start': j[0], \n",
    "    \t\t\t'end':j[1]}\n",
    "    time_array.append(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '2010_4_flare_hek',\n",
       " 'start': Timestamp('2010-05-01 00:00:00', freq='M'),\n",
       " 'end': Timestamp('2010-05-31 00:00:00', freq='M')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_files():\n",
    "\tfor file in time_array[:1]:\n",
    "\t\tinfile = None\n",
    "\t\tname = file['name']\n",
    "\t\tstart = file['start']\n",
    "\t\tend = file['end']\n",
    "\t\toutfile = tw('{}.start.pickle'.format(name))\n",
    "\t\treturn(infile,outfile,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " 'flare_hekQ.working/2010_4_flare_hek.start.pickle',\n",
       " Timestamp('2010-05-01 00:00:00', freq='M'),\n",
       " Timestamp('2010-05-31 00:00:00', freq='M'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_call = create_initial_files()\n",
    "first_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_request(infile, outfile, start, end):\n",
    "\n",
    "\n",
    "\t# pickle.dump({'start': start, 'end': end, 'event_type': 'FL'}, open(outfile, 'wb'))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @transform(create_request, suffix('.start.pickle'), \"_flares_hek_result.pickle\")\n",
    "def download_data(infile, outfile):\n",
    "\t\n",
    "\tstart_file = pickle.load(open(infile, 'rb'))\n",
    "\n",
    "\tclient = hek.HEKClient()\n",
    "\n",
    "\tevent_type = start_file['event_type']\n",
    "\n",
    "\ttstart = start_file['start']\n",
    "\n",
    "\ttend = start_file['end']\n",
    "\n",
    "\t# print('started {}'.format(tstart))\n",
    "\n",
    "\t# time_range = TimeRange(t_start, t_end)\n",
    "\n",
    "\t# tstart = time_range.start\n",
    "\t# tend = time_range.end\n",
    "\n",
    "\tAR_results = client.search(hek.attrs.Time(tstart, tend),\n",
    "\t                           hek.attrs.EventType(event_type))\n",
    "\n",
    "\tpickle.dump(AR_results, open(outfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_range':    <sunpy.time.timerange.TimeRange object at 0x7efcab3e0850>\n",
       "     Start: 2010-01-01 00:00:00\n",
       "     End:   2010-12-31 00:00:00\n",
       "     Center:2010-07-02 00:00:00\n",
       "     Duration:364.0 days or\n",
       "            8736.0 hours or\n",
       "            524160.0 minutes or\n",
       "            31449600.0 seconds,\n",
       " 'class_filter_start': 'C1',\n",
       " 'class_filter_end': 'C9.9'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_HEK_FL_result(infile, outfile):\n",
    "\n",
    "\t    # want to condense the results of the query into a more manageable\n",
    "\t    # dictionary\n",
    "\t    # keep event data, start time, peak time, end time, GOES-class,\n",
    "\t    # location, active region source (as per GOES list standard)\n",
    "\t    # make this into a list of dictionaries\n",
    "\n",
    "\tgoes_results = pickle.load(open(infile,'rb'))\n",
    "\n",
    "\tgoes_event_list = []\n",
    "\n",
    "\tfor r in goes_results:\n",
    "\t\ttry:\n",
    "\t\t\thgc_poly_string = r['hgc_bbox']\n",
    "\t\t\tsep_coord_from_string_hgc = re.split('[(-)]+', hgc_poly_string)\n",
    "\t\t\tsep_coord_from_string_hgc = re.split('[(-)]+', hgc_poly_string)\n",
    "\t\t\tonly_coord_string_list_hgc = sep_coord_from_string_hgc[1].split(',')\n",
    "\t\t\tthis_coord_array_hgc = []\n",
    "\t\t\tfor coord_pair_string_hgc in only_coord_string_list_hgc:\n",
    "\t\t\t\tnumerical_coord_pairs_hgc = [np.float(coord_pair_string_hgc.split(' ')[0]), np.float(coord_pair_string_hgc.split(' ')[1])]\n",
    "\t\t\t\tthis_coord_array_hgc.append(numerical_coord_pairs_hgc)\n",
    "\t\texcept:\n",
    "\t\t\tthis_coord_array_hgc = [0]\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\thpc_poly_string = r['hpc_bbox']\n",
    "\t\t\tsep_coord_from_string_hpc = re.split('[(-)]+', hpc_poly_string)\n",
    "\t\t\tsep_coord_from_string_hpc = re.split('[(-)]+', hpc_poly_string)\n",
    "\t\t\tonly_coord_string_list_hpc = sep_coord_from_string_hpc[1].split(',')\n",
    "\t\t\tthis_coord_array_hpc = []\n",
    "\t\t\tfor coord_pair_string_hpc in only_coord_string_list_hpc:\n",
    "\t\t\t\tnumerical_coord_pairs_hpc = [np.float(coord_pair_string_hpc.split(' ')[0]), np.float(coord_pair_string_hpc.split(' ')[1])]\n",
    "\t\t\t\tthis_coord_array_hpc.append(numerical_coord_pairs_hpc)\n",
    "\t\texcept:\n",
    "\t\t\tthis_coord_array_hpc = [0]\n",
    "\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\thgs_poly_string = r['hgs_bbox']\n",
    "\t\t\tsep_coord_from_string_hgs = re.split('[(-)]+', hgs_poly_string)\n",
    "\t\t\tsep_coord_from_string_hgs = re.split('[(-)]+', hgs_poly_string)\n",
    "\t\t\tonly_coord_string_list_hgs = sep_coord_from_string_hgs[1].split(',')\n",
    "\t\t\tthis_coord_array_hgs = []\n",
    "\t\t\tfor coord_pair_string_hgs in only_coord_string_list_hgs:\n",
    "\t\t\t\tnumerical_coord_pairs_hgs = [np.float(coord_pair_string_hgs.split(' ')[0]), np.float(coord_pair_string_hgs.split(' ')[1])]\n",
    "\t\t\t\tthis_coord_array_hgs.append(numerical_coord_pairs_hgs)\n",
    "\t\texcept:\n",
    "\t\t\tthis_coord_array_hgs = [0]\n",
    "\t\t\t\n",
    "\t\tif r['noposition'] == 'true':\n",
    "\t\t\tflare_loc_bool = 1\n",
    "\t\telse:\n",
    "\t\t\tflare_loc_bool = 0\n",
    "\n",
    "\t\tgoes_event = {\n",
    "\t\t\t'event_date': parse_time(r['event_starttime']).strftime(\n",
    "\t\t\t    '%Y-%m-%d'),\n",
    "\t\t\t'start_time': parse_time(r['event_starttime']),\n",
    "\t\t\t'peak_time': parse_time(r['event_peaktime']),\n",
    "\t\t\t'end_time': parse_time(r['event_endtime']),\n",
    "\t\t\t'goes_class': str(r['fl_goescls']),\n",
    "\t\t\t'AR_num': r['ar_noaanum'],\n",
    "\t\t\t'hgs_x': r['hgs_x'],\n",
    "\t\t\t'hgs_y': r['hgs_y'],\n",
    "\t\t\t'hgs_bbox_poly': this_coord_array_hgs,\n",
    "\t\t\t'hgc_x': r['hgc_x'],\n",
    "\t\t\t'hgc_y': r['hgc_y'],\n",
    "\t\t\t'hgc_bbox_poly': this_coord_array_hgc,\n",
    "\t\t\t'hpc_x': r['hpc_x'],\n",
    "\t\t\t'hpc_y': r['hpc_y'],\n",
    "\t\t\t'hpc_bbox_poly': this_coord_array_hpc,\n",
    "\t\t\t'event_type': r['event_type'],\n",
    "\t\t\t'telescope_used': r['obs_observatory'],\n",
    "\t\t\t'id_institute': r['frm_institute'],\n",
    "\t\t\t'id_team': r['frm_identifier'],\n",
    "\t\t\t'search_instrument': r['search_instrument'],\n",
    "\t\t\t'search_channel': r['search_channelid'],\n",
    "\t\t\t'noposition': flare_loc_bool \n",
    "\t\t\t}\n",
    "\t\tgoes_event_list.append(goes_event)\n",
    "\n",
    "\tdf = pd.DataFrame(goes_event_list)\n",
    "\n",
    "\tpickle.dump(df, open(outfile, 'wb'))\n",
    "\n",
    "\t# print('Ended {}'.format(tstart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@merge(parse_HEK_FL_result, 'hek_flare_db.pickle',output_dir=f'{dataconfig.DATA_DIR_PRODUCTS}')\n",
    "def merge_hek_query_per_month(infiles, outfile):\n",
    "\tmerged_df_list = []\n",
    "\n",
    "\tfor infile in infiles:\n",
    "\t\tinput_data = pickle.load(open(infile, 'rb'))\n",
    "\t\tmerged_df_list.append(input_data)\n",
    "        \n",
    "\tmerged_df = pd.concat(merged_df_list)\n",
    "\n",
    "\tmerged_df = merged_df.sort_values('start_time')\n",
    "\n",
    "\tmerged_df = merged_df.reset_index(drop = True)\n",
    "\n",
    "\tpickle.dump(merged_df, open(outfile, 'wb'))\n",
    "\n",
    "pipeline_run([merge_hek_query_per_month], multiprocess = 10, verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = f'{2015}-01-01'\n",
    "tend = f'{2015}-01-31'\n",
    "\n",
    "search_result = client.search(hek.attrs.Time(tstart, tend),\n",
    "\t                           hek.attrs.EventType('FL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['hpc_bbox',\n",
    "                'hgs_bbox',\n",
    "                'hgc_bbox',\n",
    "                'hgc_coord',\n",
    "                'event_type',\n",
    "                'noposition',\n",
    "                'obs_channelid',\n",
    "                'hpc_y',\n",
    "                'hpc_x',\n",
    "                'search_instrument',\n",
    "                'ar_noaanum',\n",
    "                'hgs_y',\n",
    "                'hgs_x',\n",
    "                'event_starttime',\n",
    "                'event_endtime',\n",
    "                'event_peaktime',\n",
    "                'fl_goescls',\n",
    "                'hgs_coord',\n",
    "                'obs_observatory',\n",
    "                'search_observatory'\n",
    "                \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SDO      1737\n",
       "GOES      192\n",
       "MAVEN      45\n",
       "IRIS        4\n",
       "Name: search_observatory, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.to_pandas()[keep_columns].search_observatory.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_thumburl\n",
      "comment_count\n",
      "hpc_bbox\n",
      "frm_humanflag\n",
      "hgc_coord\n",
      "event_coordsys\n",
      "obs_levelnum\n",
      "hpc_coord\n",
      "event_npixels\n",
      "gs_imageurl\n",
      "ar_polarity\n",
      "frm_paramset\n",
      "hrc_coord\n",
      "event_starttime\n",
      "ar_mtwilsoncls\n",
      "event_type\n",
      "intensmin\n",
      "fl_fluence\n",
      "obs_meanwavel\n",
      "frm_url\n",
      "skel_chaincode\n",
      "bound_chaincode\n",
      "noposition\n",
      "fl_fluenceunit\n",
      "active\n",
      "intensmax\n",
      "frm_versionnumber\n",
      "fl_peaktempunit\n",
      "fl_halphaclass\n",
      "area_uncert\n",
      "obs_dataprepurl\n",
      "hpc_geom\n",
      "hgc_bbox\n",
      "intensmedian\n",
      "chaincodetype\n",
      "obs_channelid\n",
      "event_clippedspatial\n",
      "ar_noaaclass\n",
      "SOL_standard\n",
      "event_avg_rating\n",
      "eventtype\n",
      "intensunit\n",
      "hpc_boundcc\n",
      "event_mapurl\n",
      "frm_contact\n",
      "ar_penumbracls\n",
      "intensmean\n",
      "bound_ccstartc1\n",
      "frm_name\n",
      "area_atdiskcenter\n",
      "frm_identifier\n",
      "obs_observatory\n",
      "event_description\n",
      "boundbox_c2ur\n",
      "obs_firstprocessingdate\n",
      "boundbox_c2ll\n",
      "frm_institute\n",
      "hrc_bbox\n",
      "refs_orig\n",
      "ar_mcintoshcls\n",
      "event_maskurl\n",
      "bound_ccstartc2\n",
      "gs_movieurl\n",
      "event_score\n",
      "skel_startc2\n",
      "skel_startc1\n",
      "fl_efoldtime\n",
      "event_expires\n",
      "fl_efoldtimeunit\n",
      "hrc_boundcc\n",
      "event_probability\n",
      "intensvar\n",
      "frm_daterun\n",
      "event_coordunit\n",
      "hpc_y\n",
      "hpc_x\n",
      "search_instrument\n",
      "ar_numspots\n",
      "kb_archivdate\n",
      "kb_archivist\n",
      "intenstotal\n",
      "sum_overlap_scores\n",
      "hgs_boundcc\n",
      "intensskew\n",
      "obs_includesnrt\n",
      "rasterscan\n",
      "obs_wavelunit\n",
      "kb_archivid\n",
      "search_frm_name\n",
      "boundbox_c1ur\n",
      "ar_noaanum\n",
      "area_atdiskcenteruncert\n",
      "boundbox_c1ll\n",
      "event_importance_num_ratings\n",
      "ar_compactnesscls\n",
      "skel_curvature\n",
      "event_testflag\n",
      "event_c2error\n",
      "hrc_r\n",
      "skel_nsteps\n",
      "hgs_y\n",
      "obs_title\n",
      "fl_peakemunit\n",
      "hgs_x\n",
      "hcr_checked\n",
      "frm_specificid\n",
      "event_title\n",
      "obs_instrument\n",
      "event_c1error\n",
      "revision\n",
      "hpc_radius\n",
      "event_endtime\n",
      "event_importance\n",
      "event_coord2\n",
      "event_coord3\n",
      "event_coord1\n",
      "search_observatory\n",
      "area_raw\n",
      "concept\n",
      "solar_object_locator\n",
      "event_pixelunit\n",
      "hgc_boundcc\n",
      "fl_peakflux\n",
      "hgc_x\n",
      "hrc_a\n",
      "event_peaktime\n",
      "hgc_y\n",
      "gs_galleryid\n",
      "fl_goescls\n",
      "hgs_coord\n",
      "ar_zurichcls\n",
      "bound_ccnsteps\n",
      "intenskurt\n",
      "event_clippedtemporal\n",
      "fl_peakfluxunit\n",
      "fl_peakem\n",
      "rasterscantype\n",
      "search_channelid\n",
      "fl_peaktemp\n",
      "hgs_bbox\n",
      "area_unit\n",
      "obs_lastprocessingdate\n",
      "refs\n"
     ]
    }
   ],
   "source": [
    "for element in search_result.to_pandas().columns:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HEKTable' object has no attribute 'unstack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-337a866e754d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'HEKTable' object has no attribute 'unstack'"
     ]
    }
   ],
   "source": [
    "# new_df = pd.DataFrame(search_result.unstack()).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @transform(create_request, suffix('.start.pickle'), \"_goes_HEK_result.pickle\")\n",
    "def download_data(infile, outfile):\n",
    "\tstart_file = pickle.load(open(infile, 'rb'))\n",
    "\n",
    "\tclient = hek.HEKClient()\n",
    "\tevent_type = 'FL'\n",
    "\n",
    "\ttstart = start_file['time_range'].start\n",
    "\ttend = start_file['time_range'].end\n",
    "\n",
    "\tgoes_class_filter = start_file['class_filter_start']\n",
    "\n",
    "\tgoes_class_filter2 = start_file['class_filter_end']\n",
    "\n",
    "\n",
    "\n",
    "\t# query the HEK for a list of events detected by the GOES instrument\n",
    "\t# between tstart and tend (using a GOES-class filter)\n",
    "\tif goes_class_filter:\n",
    "\t    goes_results = client.search(hek.attrs.Time(tstart, tend),\n",
    "\t                           hek.attrs.EventType(event_type),\n",
    "\t                           hek.attrs.FL.GOESCls > goes_class_filter,\n",
    "\t                           hek.attrs.FL.GOESCls < goes_class_filter2,\n",
    "\t                           hek.attrs.OBS.Observatory == 'GOES')\n",
    "\telse:\n",
    "\t    goes_results = client.search(hek.attrs.Time(tstart, tend),\n",
    "\t                           hek.attrs.EventType(event_type),\n",
    "\t                           hek.attrs.OBS.Observatory == 'GOES')\n",
    "\n",
    "\tpickle.dump(goes_results, open(outfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiadl_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
